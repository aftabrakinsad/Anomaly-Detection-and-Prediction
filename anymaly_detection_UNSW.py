# -*- coding: utf-8 -*-
"""Aanymaly_detection_UNSW.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1_8ejD6_mMgqsp8G2E-lFPrg34iX84LQt
"""

# Commented out IPython magic to ensure Python compatibility.
import numpy as np
import pandas as pd
from sklearn.ensemble import RandomForestClassifier
from sklearn.neighbors import KNeighborsClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.svm import SVC
from xgboost import XGBClassifier
from sklearn.model_selection import train_test_split, cross_val_score
from sklearn.preprocessing import LabelEncoder
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, roc_curve, auc
from sklearn.ensemble import StackingClassifier

import matplotlib.pyplot as plt
import seaborn as sns
# %matplotlib inline
sns.set(style="whitegrid")

# Load UNSW-NB15 dataset
train_file_path = '/content/UNSW_NB15_testing-set.csv'
test_file_path = '/content/UNSW_NB15_training-set.csv'

df = pd.read_csv(train_file_path)
test_df = pd.read_csv(test_file_path)

# Inspect the columns to identify the label column and features
print(df.columns)

# Strip any whitespace from column names to avoid issues
df.columns = df.columns.str.strip()
test_df.columns = test_df.columns.str.strip()

# Data transformations
# Map normal to 0, all other attacks to 1
df['label'] = df['label'].apply(lambda x: 0 if x == 0 else 1)
test_df['label'] = test_df['label'].apply(lambda x: 0 if x == 0 else 1)

# Identify categorical features and encode them
categorical_features = ['proto', 'service', 'state']
df = pd.get_dummies(df, columns=categorical_features)
test_df = pd.get_dummies(test_df, columns=categorical_features)

# Align the test set to have the same columns as the training set
test_df = test_df.reindex(columns=df.columns, fill_value=0)

# Selecting a subset of features for demonstration; adjust as needed
selected_features = [
    'dur', 'sbytes', 'dbytes', 'sttl', 'dttl', 'sloss', 'dloss',
    'service_dns', 'service_ftp', 'service_http', 'state_INT'
]

# Ensure selected features are present in the encoded dataframe
to_fit = df[selected_features]
test_set = test_df[selected_features]

# Create target classifications
binary_y = df['label']
test_binary_y = test_df['label']

# Split data into training and validation sets
binary_train_X, binary_val_X, binary_train_y, binary_val_y = train_test_split(to_fit, binary_y, test_size=0.6, random_state=42)

# Define base classifiers
base_classifiers = [
    ('lr', LogisticRegression(max_iter=1000)),
    ('knn', KNeighborsClassifier()),
    ('rf', RandomForestClassifier(n_estimators=100)),
    ('svc', SVC(probability=True)),
    ('xgb', XGBClassifier(use_label_encoder=False, eval_metric='logloss'))
]

# Stacking Classifier
stacking_clf = StackingClassifier(estimators=base_classifiers, final_estimator=RandomForestClassifier(n_estimators=100))

# Model fitting
stacking_clf.fit(binary_train_X, binary_train_y)
stacking_binary_predictions = stacking_clf.predict(binary_val_X)

# Evaluate the model
base_rf_score = accuracy_score(stacking_binary_predictions, binary_val_y)
print("Binary Classification Accuracy on UNSW-NB15 (Validation Set):", base_rf_score)

# Evaluate on the test set
test_predictions = stacking_clf.predict(test_set)
test_rf_score = accuracy_score(test_predictions, test_binary_y)
print("Binary Classification Accuracy on UNSW-NB15 (Test Set):", test_rf_score)

accuracy_scores = cross_val_score(stacking_clf, binary_train_X, binary_train_y, cv=5)
print("Cross-validated Accuracy Scores:", accuracy_scores)

from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, roc_curve, auc

stacking_binary_predictions = stacking_clf.predict(binary_val_X)

precision = precision_score(binary_val_y, stacking_binary_predictions)
recall = recall_score(binary_val_y, stacking_binary_predictions)
f1 = f1_score(binary_val_y, stacking_binary_predictions)

print("Precision:", precision)
print("Recall:", recall)
print("F1 Score:", f1)

metrics = ['Precision', 'Recall', 'F1 Score']
values = [precision, recall, f1]

plt.figure(figsize=(8, 5))
ax = sns.barplot(x=metrics, y=values, color="blue")

for i, v in enumerate(values):
    ax.text(i, v + 0.02, f"{v:.2f}", color='black', ha='center')

plt.title('Model Performance Metrics')
plt.ylabel('Score')
plt.ylim(0, 1.1)
plt.show()

conf_matrix = confusion_matrix(binary_val_y, stacking_binary_predictions)
print("Confusion Matrix:\n", conf_matrix)

labels = ['Negative', 'Positive']

plt.figure(figsize=(8, 6))
sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=labels, yticklabels=labels)
plt.title('Confusion Matrix')
plt.xlabel('Predicted Label')
plt.ylabel('True Label')
plt.show()

stacking_binary_probabilities = stacking_clf.predict_proba(binary_val_X)[:, 1]

fpr, tpr, thresholds = roc_curve(binary_val_y, stacking_binary_probabilities)

auc_score = auc(fpr, tpr)
print("AUC Score:", auc_score)

plt.figure(figsize=(8, 6))
plt.plot(fpr, tpr, color='blue', lw=2, label='ROC curve (AUC = %0.2f)' % auc_score)
plt.plot([0, 1], [0, 1], color='gray', linestyle='--')
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.05])
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('Receiver Operating Characteristic (ROC) Curve')
plt.legend(loc="lower right")
plt.show()
